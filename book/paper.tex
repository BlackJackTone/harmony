\documentclass{report}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{framed}
\usepackage{tcolorbox}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{comment}
\usepackage{amsmath}

\widowpenalty 10000
\clubpenalty 10000
\tolerance=9999
\newcommand{\tm}{\raisebox{.9ex}{\tiny tm}}

% \renewcommand{\topfraction}{.99}
% \renewcommand{\bottomfraction}{.99}
% \renewcommand{\textfraction}{.01}
% \renewcommand{\floatpagefraction}{.9}
% \renewcommand{\dbltopfraction}{.99}
% \renewcommand{\dblfloatpagefraction}{.9}

\newenvironment{code}{
\tcolorbox
}{
\endtcolorbox
}

\title{Concurrent Programming with CXL}
\author{RVR and possibly others}

\begin{document}

\maketitle

\chapter{On Concurrent Programming}

Programming with concurrency is hard.  On the one hand concurrency
can make programs faster than sequential ones, but having multiple
processes concurrently read and update shared variables and
synchronize with one another makes programs more complicated than
programs where only one thing happens at a time.  Why is this?
There are, at least, two reasons:
\begin{itemize}
\item The execution of a sequential program is mostly \emph{deterministic}.
If you run it twice with the same input, the same things will happen.
Bugs are typically easily reproducible.
\item Each statement and each function can be thought of as happening
\emph{atomically} because there is no other activity interfering with
their execution.
\end{itemize}
The lack of determinism and atomicity in concurrent programs make them
not only hard to reason about, but also hard to test.
Running the same test of concurrent code twice is likely to produce
two different results.  More problematically, a test may trigger a
bug only for certain ``lucky'' executions.  Due to the probabilistic
nature of concurrent code, some bugs may be highly unlikely to get
triggered even when running a test millions of times.  And even if
a bug does get triggered, the source of the bug may be hard to find
because it is hard to reproduce.

This book is intended to help people with understanding and
developing concurrent code.  In particular, it uses a new tool
called CXL that helps with \emph{testing} concurrent code.
The approach is based on \emph{model checking}: instead of relying
on luck, CXL will run \emph{all possible executions} of a particular
test program.  So even if a bug is unlikely to occur, if the test
\emph{can} expose the bug it \emph{will}.  Importantly, if the bug is
found, the model checker precisely shows how to trigger it in
the smallest number of steps.

Model checking is not a replacement for formal verification.  Formal
verification proves that a program is correct.  Model checking only
verifies that a program is correct for some \emph{model}.  Think of
a model as a test program.  Because model checking tries every possible
execution, this means that the test program needs to be relatively
simple.  In particular, it needs to have a relatively small number of
reachable states.
If the model is too large, it may run for longer than we may care to
wait for or even run out of memory.

So why is this useful?  Consider, for example, a sorting algorithm.
Now suppose we create a test program, a model, that tries sorting
\emph{all} lists of up to five numbers chosen from the set \{ 1,
2, 3, 4, 5 \}.  Model checking proves that for those particular
scenarios the sorting algorithm works: the output is a sorted
permutation of the input.  In some sense it is an excellent test:
it will have considered all corner cases, including lists where all
numbers are the same, lists that are already sorted or reversely
sorted, etc.  If there is a bug in the sorting algorithm, most
likely it would be triggered and the model checker would produce a
scenario that would make it easy to find the source of the bug.
However, if the model checker does not find any bugs, we do not
know for sure that the algorithm works for lists with more than
five numbers or for lists that have values other than the numbers
1 through 5.  Still, we would expect that the likelihood that there
are bugs remaining in the sorting algorithm is small.

But model checking can also help with proving an algorithm correct.
The reason is that the correctness of many programs is built around
\emph{invariants}: predicates that must hold for every state in the
execution of a program.  A model checker can find violations of
those invariants when evaluating a model and provide valuable early
feedback to somebody who is trying to construct a proof, even an
informal one.
Throughout this book we will include examples
of such invariants as they often provide excellent insight into
why a particular algorithm works.

So what is CXL?
CXL is a concurrent programming language.  It was designed to teach
the basics of concurrent programming, but it is also useful for
testing new concurrent algorithms or even sequential and distributed
algorithms.  CXL programs are not intended to be ``run'' like programs
in most other programming languages---instead CXL programs are
model checked to test that the program has certain desirable
properties and does not suffer from bugs.

The syntax and semantics of CXL is similar to that of Python.
Python is familiar to many programmers and is easy to learn and
use.  We will assume that the reader is familiar with the basics
of Python programming.  We also will assume that the reader
understand some basics of machine architecture and how programs
are executed.  For example, we assume that the reader is familiar
with the concepts of CPU, memory, register, and stack.

\chapter{Introduction to Programming with CXL}

Like Python, CXL is an imperative,
dynamically typed, and garbage collected programming language.
There are also some important differences:
\begin{itemize}
\item Every statement in CXL must be terminated by a semicolon
(even \texttt{while} statements and \texttt{def} statements);
in Python semicolons are optional and rarely used;
\item Correct indentation in CXL is encouraged but optional;
\item Python is object-oriented; CXL is not;
\item CXL does not (currently) support floating point;
\item CXL does not support I/O of any kind;
\item CXL only supports basic operator precedence or associativity.
Use parentheses liberally to remove ambiguity.
\end{itemize}
There are also many unimportant ones that you will discover as
you get more familiar with programming in CXL.

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{triangle.cxl}
\end{code}
\caption{Computing triangle numbers.}
\label{fig:triangle}
\end{figure}

Figure~\ref{fig:triangle} gives a simple example of a CXL program.
It is sequential and has a method \texttt{square} that takes
an integer number as argument.  Each method has a variable called
\texttt{result} that eventually contains the result of the
method (there is no \texttt{return} statement in CXL).  The method
also has a variable called \texttt{n} containing the value of the
argument.  The \texttt{x..y} notation generates a set containing the numbers
from~\texttt{x} to~\texttt{y} (inclusive).  The last two lines in the program are
the most interesting.
They assign to \texttt{x} some unspecified value in the range \texttt{0..N}
and then verifies that $\mathtt{triangle}(x)$ equals $x(x+1)/2$.

``Running'' this CXL program will try all possible executions, which
includes all possible values for $x$.  Try it out:

\begin{code}
\begin{verbatim}
$ ./cxl triangle.cxl
#states = 13
no issues found
$
\end{verbatim}
\end{code}

Essentially, the $\texttt{choose}(S)$
operator provides the input to the program by selecting some value from the
set~$S$, while the $\texttt{assert}$ statement checks that the output is
correct.  If the program is correct, the output of CXL is the size of the
``state graph'' (13 states in this case).  If not, CXL also
reports what went wrong, typically by displaying a summary of an execution in
which something went wrong.

\begin{quote}
Experiment!
\begin{itemize}
\item See what happens if, instead of initializing \texttt{result} to 0,
you initialize it to 1.
\item Write a similar program that computes squares or factorials.
\end{itemize}
\end{quote}

\chapter{The Problem of Concurrent Programming}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{Up.cxl}
\end{code}
\caption{Incrementing twice in parallel.}
\label{fig:inc}
\end{figure}

Concurrent programming, aka multithreaded programming, involves multiple
processes running in parallel while sharing variables.
Figure~\ref{fig:inc} presents a simple example.
The program
initializes two shared variables: an integer \texttt{count} and
an array \texttt{done} with two booleans.
Method \texttt{incrementer} takes a parameter called \texttt{self}.
It increments \texttt{count} and sets \texttt{done[self]} to \texttt{True}.
Method \texttt{main} waits for the processes to finish by polling
both \texttt{done} flags.
After that, it verifies that the value of \texttt{count} equals 2.  If not,
it reports the actual value of \texttt{count}.
The program spawns three processes.
The first runs \texttt{incrementer(0)}, the second runs
\texttt{incrementer(1)}, and the last runs \texttt{main()}.

\begin{quote}
What will happen?
\begin{itemize}
\item Before you run the program, what do you think will happen?  Is the
program correct in that \texttt{count} will always end up being 2?
\item What are the possible values of \texttt{count} at the time of the
\texttt{assert} statement?
(You may assume that \texttt{load} and \texttt{store} instructions of the
underlying architecture are atomic---in fact they are.)
\end{itemize}
\end{quote}

What is going on is that the CXL program is compiled to machine instructions,
and it is the machine instructions that are executed by the underlying CXL
machine.  The details of this appear in Chapter~\ref{ch:cxlmachine},
but suffice it to
say that the machine has instructions that load values from memory and store
values into memory.  Importantly, it does not have instructions to atomically
increment or decrement values in memory locations.
So to increment a value in memory,
the machine must do at least three machine instructions.  Conceptually:
\begin{enumerate}
\item load the value from the memory location;
\item add 1 to the value;
\item store the value to the memory location.
\end{enumerate}

When running multiple processes, each essentially runs an instantiation of
the machine, and they do so in parallel.  As they execute, their machine
instructions are interleaved in unspecified and often random ways.
A program is correct if it works for any interleaving.
In fact, CXL will try all possible interleavings of the processes
executing machine instructions.

The following is a possible interleaving of incrementers~0 and~1:
\begin{enumerate}
\item incrementer 0 loads the value of \texttt{count}, which is 0;
\item incrementer 1 loads the value of \texttt{count}, which is still 0;
\item incrementer 1 adds one to the value that it loaded (0), and
stores $1$ into \texttt{count};
\item incrementer 0 adds one to the value that it loaded (0), and
stores $1$ into \texttt{count};
\item incrementer 0 sets \texttt{upDone} to \texttt{True};
\item incrementer 1 sets \texttt{upDone} to \texttt{True}.
\end{enumerate}

The result in this particular interleaving is that \texttt{count} ends up
being 1.  When running CXL, it will
report violations of assertions.  It also provides an example
of an interleaving, like the one above, in which an assertion fails.

If one thinks of the assertion as providing the specification of the
program, then clearly its implementation does not satisfy its specification.
Either the specification or the implementation (or both) must have a bug.
We could change the specification by changing the assertion as follows:

\begin{code}
\begin{verbatim}
    assert (count == 1) or (count == 2);
\end{verbatim}
\end{code}

This would fix the issue, but more likely it is the program that must
be fixed.

\begin{quote}
Can you think of a fix to the program?  You can try it out and see
if it works or not.
\end{quote}

\chapter{CXL Values}
\label{ch:cxlvalues}

CXL programs manipulate CXL values.
CXL values are recursively defined:
they include booleans (\texttt{False} and \texttt{True}),
integers (but not floating point numbers),
strings (enclosed by double quotes),
sets of CXL values,
and dictionaries that map CXL values to other CXL values.
%
Another type of CXL value is the \emph{atom}.  It is essentially
just a name.  An atom is denoted using a period followed by the
name.  For example, \texttt{.main} is an atom.

CXL makes extensive use of dictionaries.  Their syntax and properties
are a little different from Python.
A dictionary maps CXL values, known as \emph{keys}, to CXL values.
Unlike Python, any CXL value can be a key, including another
dictionary.
CXL dictionaries are written as
$\mathtt{dict}\{ k_0: v_0, ~ k_1: v_1, ~ ... \}$.
If \texttt{d} is a dictionary, and \texttt{k} is a key, then the
following expression retrieves the CXL value that $k$ maps to:
\begin{code}
\begin{verbatim}
d k
\end{verbatim}
\end{code}
This is unfamiliar to Python programers, but in CXL square brackets can be used
in the same way as parentheses, so you can express it in the more familiar form:
\begin{code}
\begin{verbatim}
d[k]
\end{verbatim}
\end{code}
However, if \texttt{d = dict\{ .count: 3 \}}, then you can write
can write \texttt{d.count} (which has value 3) instead of having to write
\texttt{d[.count]} (although both will work).
The meaning of \texttt{d a b c ...} is \texttt{((((d a) b) c) ...)}.

Tuples are special forms of dictionaries where the keys are
the indexes into the tuple.  For example, the tuple
\texttt{(5, False)} is the same CXL value as
\texttt{dict\{ 0: 5, 1: False \}}.
The empty tuple \texttt{()} is the same value as \texttt{dict\{\}}.
Note that this is different from the empty set, which is \texttt{\{\}}.
As in Python, you can create singleton tuples by including a comma.
For example, \texttt{(1,)}.

Again, square brackets and parentheses work the same in CXL, so
\texttt{[a, b, c]} (which looks like a Python list)
is the same CXL value as \texttt{(a, b, c)} (which looks like a Python tuple),
which in turn is the same CXL value as \texttt{dict\{ 0:a, 1:b, 2:c \}}.
So if \texttt{x == [ False, True ]},
then \texttt{x[0] == False} and \texttt{x[1] == True}, just like in Python.
However, when creating a singleton list, make sure you include the
comma, as in \texttt{[False,]}.

CXL is not an object-oriented language, so objects don't have
built-in methods.  However, CXL does have some powerful operators to
make up for some of that.
For example, dictionaries have two handy unary operators.
If \texttt{d} is a
dictionary, then \texttt{keys~d} (or equivalently \texttt{keys(d)})
returns the set of keys and \texttt{len~d} returns the size of
this set.

\chapter{The CXL Machine}
\label{ch:cxlmachine}

\begin{figure}
\begin{code}
\begin{verbatim}
Up.cxl:1 def incrementer(self):
    0 Jump 39
    1 Frame incrementer ['self'] 12
Up.cxl:2     count = count + 1;
    2 Push 1
    3 PushAddress count
    4 Load 1
    5 2-ary +
    6 PushAddress count
    7 Store 1
Up.cxl:3     done[self] = True;
    8 Push True
    9 PushVar self
   10 PushAddress done
   11 Store 2
   12 Return
\end{verbatim}
\end{code}
\caption{The first part of the machine code corresponding to Figure~\ref{fig:inc}.}
\label{fig:inccode}
\end{figure}

\begin{figure}
\begin{code}
\begin{verbatim}
CXL Assertion failed ('assert', 'Up.cxl', 9, 5) 1
#states = 79
==== Safety violation ====
__init__/() [0,39-56]       57 dict{ .count:0, .done:dict{ 0:False, 1:False } }
incrementer/0 [1-6]          7 dict{ .count:0, .done:dict{ 0:False, 1:False } }
incrementer/1 [1-11]        12 dict{ .count:1, .done:dict{ 0:False, 1:True  } }
incrementer/0 [7-11]        12 dict{ .count:1, .done:dict{ 0:True,  1:True  } }
main/() [14-19,22-27,29-36] 37 dict{ .count:1, .done:dict{ 0:True,  1:True  } }
\end{verbatim}
\end{code}
\caption{The output of running Figure~\ref{fig:inc}.}
\label{fig:incoutput}
\end{figure}

Before we delve into how to solve synchronization problems, it is important
to know a bit about the underlying machine.  A CXL program is translated
into a list of machine instructions that the CXL machine executes.
The CXL machine is not an ordinary virtual machine, but its architecture
is nonetheless representative of conventional machines such as hardware
with memory and CPUs and virtual machines such as the Java Virtual Machine.

Instead of bits and bytes, a CXL machine manipulates CXL values.
A CXL machine has the following components:
\begin{itemize}
\item Code:  This is an immutable and finite list of CXL machine instructions,
generated from a CXL program.  The types of instructions will be described later.
\item Shared memory: A CXL machine has just one memory location containing
an CXL value.
\item Processes:  Any process
can spawn an unbounded number of other processes and processes may terminate.
Each process has an immutable (but not necessarily unique) \emph{name tag},
a program counter, a stack of CXL values,
and a single mutable general purpose \emph{register} that contains a CXL value.
\end{itemize}

A name tag consists of the name of the main method of the process,
along with an optional tag specified in the \texttt{spawn} statement.
The default tag is the first argument to the method.
In Figure~\ref{fig:inc}, the created processes have name tags
\texttt{incrementer/0}, \texttt{incrementer/1}, and \texttt{main/()}.

The state of a process is called a \emph{context}: it contains the value of
its name tag, program counter, stack, and register.
The state of the CXL machine
consists of the value of its memory and the multiset (or \emph{bag}) of
contexts.  It is a multiset of contexts because two different processes can
be in the same state.
The initial state of the CXL memory is the empty dictionary, \texttt{()}.
The context bag has an initial context in it with name tag
\texttt{\_\_main\_\_/()}, pc 0, register \texttt{()}, and an empty stack.
Each machine instruction updates the state in some way.
Figure~\ref{fig:incstate} shows an example of a reachable state for 
the program in Figure~\ref{fig:inc}.


It may seem strange that there is only one memory location and that each
process has only one register.  However, this is not a limitation because
CXL values are unbounded trees.
Both the memory and the register of a process always contain
a dictionary that maps atoms to CXL values.  We call this a \emph{directory}.
A directory represents the state of a collection of variables named by the atoms.
%
Because directories are CXL values themselves,
directories can be organized into a tree.
Each node in the tree is then identified
by a sequence of atoms, like a path name in the file system hierarchy.  We call
such a sequence the \emph{address} of a CXL value, and it is relative to the
``root'' of the CXL value.

Compiling the code in Figure~\ref{fig:inc} results in the CXL machine code
listed in Figure~\ref{fig:inccode}.
The CXL machine is predominantly a \emph{stack machine}.
All instructions are atomically executed.
Most instructions pop values from the stack or push values onto the stack.
Initially there is one process (with name tag \texttt{\_\_init\_\_/()}
that starts executing at instruction 0 and keeps executing until the last
execution in the program to initialize the state.
In this case, the first instruction is a \texttt{JUMP} instruction that sets the
program counter to 39.
At program counter 1 is the code for the \texttt{incrementer} method.
All methods start with a \texttt{Frame} instruction and end with a \texttt{Return}
instruction.

The \texttt{Frame} instruction has three arguments:
\begin{enumerate}
\item The name of the method;
\item A list containing the names of the arguments of the method;
\item The program counter of the method's \texttt{Return} instruction.
\end{enumerate}

The code generated from \texttt{count := count + 1} in line 2 of
\texttt{Up.cxl} is as follows:

\begin{enumerate} \setcounter{enumi}{1}
\item the \texttt{Push} instruction pushes the constant 1
onto the stack of the process.
\item the \texttt{PushAddress} instruction pushes the address of
the shared variable \texttt{count} onto the stack.
\item The \texttt{Load} instruction pops the address of the
\texttt{count} variable and then pushes the value of the
\texttt{count} variable onto the stack.
\item \texttt{2-ary} is a \texttt{+} operation with 2 arguments.
It pops two values from the stack (1 and the value of \texttt{count}),
adds them and pushes the result back onto the stack.
\item The \texttt{PushAddress} instruction pushes the address of the \texttt{count}
variable onto the stack.
\item The \texttt{Store} instruction pops the address of a variable and pops
a CXL value (the sum of the \texttt{count} variable and 1) and updates the
\texttt{count} variable.
\end{enumerate}

Once initialization completes, any processes that were spawned can run.
You can think of CXL as trying every possible interleaving of processes executing
instructions.
Figure~\ref{fig:incoutput} shows the output produced by running CXL on the
\texttt{Up.cxl} program.
It starts by reporting that the assertion on line 9 in column 5 failed and that
\texttt{count} has value 1 instead of 0:
\texttt{Assertion failed (’assert’, ’Up.cxl’, 9, 5) 1}.
Next it reports an execution that failed this assertion.  The output has
four columns:
\begin{enumerate}
\item The name tag of the process;
\item The sequence of program counters of the CXL machine instructions that the process executed;
\item The current program counter of the process;
\item The contents of the shared memory.
\end{enumerate}

If we look at the middle three rows, we see that:
\begin{enumerate}
\item Process 0 executed instructions 1 through 7, loading the value of
\texttt{count} but stopping just before storing 1 into \texttt{count};
\item Process 1 executed instructions 1 through 12, storing 1 into
into \texttt{count} and storing \texttt{True} into \texttt{done[1]};
\item Process 0 continues execution, storing value 1 into \texttt{count}
and storing \texttt{True} into \texttt{done[0]}.
\end{enumerate}

This makes precise the concurrency problem that we encountered.

\chapter{Critical Sections}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{csbarebones.cxl}
\end{code}
\caption{A barebones critical section.}
\label{fig:csbarebones}
\end{figure}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{cs.cxl}
\end{code}
\caption{CXL model of a critical section.}
\label{fig:cs}
\end{figure}

Hopefully you have started thinking of how to solve the concurrency
problem and you may already have prototyped some solutions.
In this chapter we will go through a few reasonable but broken attempts.
At the heart of the problem is that we would like make sure that, when
the \texttt{count} variable is being updated, no other process is
trying to do the same thing.  We call this a \emph{critical section}: a
set of instructions where only one process is allowed to execute at a
time.

Critical sections are useful when accessing a shared data
structure, particularly when that access requires multiple underlying
machine instructions.  A counter is a very simple example of
a data structure.  A more involved one would be access to a binary tree.
Adding a node to a binary tree, or re-balancing a tree, often requires
multiple operations.  Maintaining ``consistency'' is certainly much easier
(although not necessarily impossible) if during this time no other
process also tries to access the binary tree.

A critical section is often modeled as processes in an infinite loop
entering and exiting the critical section.
Figure~\ref{fig:csbarebones} shows the CXL code.
Here \texttt{@ncs} and \texttt{@cs} are \emph{labels}, each identifying
a location in the CXL machine code.  The first thing we need to
ensure is that there cannot be two processes at the critical section.
We would like to place an assertion at the \texttt{@cs} label that
specifies that only the current process can be there.  CXL in fact
supports this.  It has an operator \texttt{atLabel $L$}, where $L$
is the atom of the label (in this case, \texttt{.cs}).  The
operator returns a bag of name tags of processes executing at that
label.  The bag is represented by a dictionary that maps each element
in the bag to the number of times the element appears in the bag.
Method \texttt{atLabel} only exists for specification purposes---do not
use it in normal code.

The assertion also makes use of the \texttt{nametag()} operator that
returns the name tag of the current process.
If you run the code through CXL, the assertion should fail because
there is no code yet for entering and exiting the critical section.

However, mutual exclusion by itself easy to ensure.
For example, we could insert the following code to enter the
critical section:
\begin{code}
\begin{verbatim}
while True:
    pass;
;
\end{verbatim}
\end{code}
This code will surely prevent two or more processes from being
at label \texttt{cs} at the same time.
But it does so by preventing \emph{any} process from reaching
the critical section.
We clearly need another property besides mutual exclusion.

Mutual exclusion is an example of a \emph{safety property}, a
property that ensures that \emph{nothing bad will happen}, in this case
two processes being in the critical section.
What we need now a \emph{liveness property}: we want to ensure that
\emph{eventually something good will happen}.
There are various possible liveness properties we could use,
but here we will propose the following informally: if some set of processes
$S$ are trying to enter the critical section and any process already in the
intersection eventually leaves, then eventually one process in $S$ will enter
the critical section.
We call this \emph{progress}.

\begin{figure}
\begin{center}
\includegraphics[width=4in]{figures/mutex.jpeg}
\end{center}
\caption{High-level state diagram specification of mutual exclusion with up to two processes.
The first number in a state gives the number of processes; the second number is the
number of processes in the critical section.}
\label{fig:mutex}
\end{figure}

In order to detect violations of progress, and other liveness problems in
algorithms in general, CXL requires that every execution must be
able to reach a state in which all processes have terminated.
Clearly, even if mutual exclusion holds in Figure~\ref{fig:csbarebones},
the spawned processes never terminate.  In order to resolve this, we
will model processes in critical sections using the framework in
Figure~\ref{fig:cs}: a process can \emph{choose} to enter a
critical section more than once, but it can also choose to terminate, even
without entering the critical section ever.
Note also that we have dropped the \texttt{@ncs} label: it would serve no
specific purpose.
Figure~\ref{fig:mutex} show a high-level state diagram of the code in
Figure~\ref{fig:cs}.

\begin{quote}
Try it out!
\begin{itemize}
\item Plug \texttt{while True: pass;;} for entering the critical section
in Figure~\ref{fig:cs} and run CXL.  It should print a trace
to a state from which a terminating state cannot be reached.
\end{itemize}
\end{quote}


\chapter{Na\"{\i}ve Attempts at Implementing Critical Sections}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{UpLock.cxl}
\end{code}
\caption{Na\"{\i}ve implementation of a shared lock.}
\label{fig:uplock}
\end{figure}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{UpFlags.cxl}
\end{code}
\caption{Na\"{\i}ve use of flags to solve mutual exclusion.}
\label{fig:upflags}
\end{figure}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{UpTurn.cxl}
\end{code}
\caption{Na\"{\i}ve use of turn variable to solve mutual exclusion.}
\label{fig:upturn}
\end{figure}

In order to have at most one process in a critical section at a time, you
probably are thinking that one might use a \emph{lock}.
That is a good thought, but how does one implement one?
Figure~\ref{fig:uplock} presents a mutual exclusion attempt based on a
na\"{\i}ve implementation of a lock.
The idea is that the lock is like a baton that at most one process can own
(or hold) at a time.
Initially the lock is not owned, indicated by lock being \texttt{False}.
To enter the critical section, a process waits until \texttt{lock} is \texttt{False}
and then sets it to \texttt{True} to indicate that the lock has been taken.
The process then executes the critical section.  Finally the process
releases the lock by setting it back to \texttt{False}.

Unfortunately, if we run the program, we find that the assertion still
fails.  Diagnosing the problem, we see that the \texttt{lock} variable
suffers from the same problem as the \texttt{count} variable
in Figure~\ref{fig:inc}: operations
on it consist of several instructions.  It is thus possible
for both processes to believe the lock is available and to obtain the lock
at the same time.

Figure~\ref{fig:upflags} presents a solution based on each process having
a flag indicating that it is trying to enter the critical section.
A process can write its own flag and read the flag of its peer.
After setting its flag, the process waits until the other process
(\texttt{1 - self}) is not trying to enter the critical section.
If we run this program, the assertion does not fail.  In fact, this
solution does prevent both processes being in the critical section at
the same time.

To see why, first note the invariant that if process $i$ is in the
critical section, then flags[i] == True.
Without loss of generality,
suppose that process~0 sets \texttt{flags[0]} at time $t_0$.
Process 0 can only reach the critical section if at some time $t_1$,
$t_1 > t_0$, it finds that \texttt{flags[1] == False}.
Because of the invariant, \texttt{flags[1] == False} implies that
process~1 is not at the critical section at time $t_1$.
Let $t_2$ be the time at which process~0 sets \texttt{flags[0]}
to \texttt{False}.  Process~0 is in the critical section sometime
between $t_1$ and $t_2$.
It is easy to see that process~1 cannot enter the critical section
between $t_1$ and $t_2$, because \texttt{flags[1] == False} at
time $t_1$.  To reach the critical section between $t_1$ and $t_2$,
it would first have to set \texttt{flags[1]} to \texttt{True} and
then wait until \texttt{flags[0] == False}.  But that does not happen
until time $t_2$.

However, the solution has a different problem called \emph{livelock}:
if both try to enter the critical section at the same time, they may
end up waiting for one another indefinitely.  Thus the solution
violates \emph{progress}.

The final na\"{\i}ve solution is based on a variable called \texttt{turn}
that alternates between 0 and 1.  When \texttt{turn = $i$}, process~$i$ can
enter the critical section, while process $1-i$ has to wait.  When done,
process~$i$ sets \texttt{turn} to $1-i$ to give the other process an
opportunity to enter.
An invariant of this solution is that while process~$i$ is in the critical
section, \texttt{turn} == $i$.
Since \texttt{turn} cannot be 0 and 1 at
the same time, mutual exclusion is satisfied.
The solution also has the nice property that
processes 0 and 1 alternate entering the critical section.
The problem with the solution is
that it also violates the \emph{progress} property:
if process~$i$ terminates instead of entering the critical section when it
is process~$i$'s turn, process $1-i$ ends up waiting indefinitely for its
turn.

\chapter{Peterson's Algorithm}
\label{ch:peterson}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../Peterson.cxl}
\end{code}
\caption{Peterson's Algorithm}
\label{fig:peterson}
\end{figure}

In 1981, Peterson came up with a beautiful solution to the mutual exclusion
problem, now known as ``Peterson's Algorithm''~\cite{Peterson81}.
The algorithm is an amalgam of the (incorrect) algorithms in
Figures~\ref{fig:upflags} and~\ref{fig:upturn}, and is presented
in Figure~\ref{fig:peterson}.
A process first indicates its interest in entering the critical section
by setting its flag.
It then politely gives way to the other process should it also want to
enter the critical section---if both do so at the same time one will
win because writes to memory in CXL are atomic.
The process continues to be polite, waiting in a \texttt{while} loop
until either the other process is nowhere near the critical section
or has given way.
Running the algorithm with CXL shows that it satisfies both mutual
exclusion and progress.

Why does it work?  We will focus here on how one might go about proving
mutual exclusion for an algorithm such as Peterson's.
For that, we have to understand a little bit more about how the CXL
machine works.
In Chapter~\ref{ch:cxlmachine} we talked about the concept of \emph{state}:
at any point of time the CXL machine is in a specific state.
Everytime a process executes a CXL machine instruction, the
state changes (if only because the program counter of the process is
updated).  We call that a \emph{step}.  Steps in CXL are atomic.

The CXL machine starts in an initial state in which there is only
one process and its program counter is~0.  A \emph{trace} is a
sequence of steps starting from the initial state.  When making a
step, there are two sources of non-determinism in CXL.  One is when
in some state more than one process can make a step.  The other is
when a process executes a \texttt{choose} operation and there is
more than one choice.

A good way to prove mutual exclusion is through induction on
the number of steps.
In such a proof, we need a so-called \emph{inductive invariant} $I$ that
implies mutual exclusion.
An inductive invariant $I$ is a predicate over state that satisfies the following:
\begin{itemize}
\item $I$ hold in the initial state.
\item For any state in which $I$ holds and any process in the
state takes a step, then $I$ also holds in the resulting state.
\end{itemize}

One candidate for such an invariant is mutual exclusion itself.
After all, it certainly holds over the initial state.
And as CXL has already determined, mutual exclusion is an invariant:
it holds over every \emph{reachable state}.
Unfortunately, it is not an \emph{inductive} invariant.
To see why, we need to consider an \emph{unreachable} state.
It is easy to construct one: let process~0 be at label \texttt{@cs}
and process~1 at the start of the \texttt{while} loop.
Also imagine that in this particular state $\mathtt{turn} = 1$.  Now let
process process~1 make a sequence of steps.  Because $\mathtt{turn} = 1$,
process~1 will break out of the while loop and also enter the critical
section, violating mutual exclusion.
So mutual exclusion is an invariant, but not an inductive invariant.
Doing a inductive proof with an invariant that is not inductive is usually
much harder than doing one with an invariant that is.

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../PetersonProof.cxl}
\end{code}
\caption{Peterson's Algorithm with Inductive Invariant}
\label{fig:petersonproof}
\end{figure}

Let $C(i) = \mathtt{flags}[1 - i] \land
\mathtt{turn} = 1 - i$, that is, the condition on the \texttt{while} loop
for process~$i$.
Let predicate $I_p(i)$ be the following.
if process $i$ is label \texttt{@cs} (i.e., process $i$ is in the critical section),
then $C(i)$ does not hold or process $1-i$ is executing after setting
$\mathtt{flags}[i]$ but still before setting \texttt{turn} to $1-i$.
More formally, $I_p(i) = \mathtt{process}(i)@cs) \Rightarrow (\lnot C(i) \lor \mathtt{process}(1-i)@gate)$.
For Peterson's Algorithm, an inductive invariant that works well is
$I_p(0) \land I_p(1)$.

Figure~\ref{fig:petersonproof} formalizes $I_p(i)$ in CXL.
The label \texttt{@gate} refers to the instruction that sets \texttt{turn} to $1-i$.
You can run Figure~\ref{fig:petersonproof} to determine
that $I_p(i)$ is indeed an invariant for $i = 0, 1$.

To see that the inductive invariant implies mutual exclusion, suppose not.  Then
when both process~0 and process~1 are in the critical section, the
following must hold:
$(\lnot C(0) \lor \mathtt{process}(1)@gate) \land
 (\lnot C(1) \lor \mathtt{process}(0)@gate)$.
We know that both flags are set.
We also know that neither process~0 nor process~1 is at label \texttt{@gate}
(because they are both at label \texttt{@cs}),
so this simplifies to $(\lnot C(0)) \land (\lnot C(1))$.
So we conclude that $\mathtt{turn} = 0 \land \mathtt{turn} = 1$, a
logical impossibility.  Thus $I_p(i)$ implies mutual exclusion.

To see that $I_p(0) \land I_p(1)$ is, in fact, an inductive invariant, first note that
it certainly holds in the initial state, because in the initial state no process
is in the critical section.
Without loss of generality, suppose $i=0$ (a benefit from the fact that the algorithm is
symmetric for both processes).  We still have to show that if we are in a state
in which $I_p(0)$ holds, then any step will result in a state in which
$I_p(0)$ still holds.
If $I_p(0)$ holds, process~0 is at label \texttt{@cs}.  If process~0
were to take a step, then in the next state process~0 would be no longer
at that label and $I_p(0)$ would hold trivially over the next state.
Therefore we only need to consider a step by process~1.

From $I_p(0)$ we know that one of the following three cases must hold before
process~1 takes a step:
\begin{enumerate}
\item \texttt{flags[1] = False};
\item \texttt{turn = 0};
\item process~1 is at label \texttt{@gate}.
\end{enumerate}

Let us consider each of these cases.
In the first case, if process~1 takes a step, there are two possibilities:
either $flags[1]$ will still be \texttt{False} (in which case the first case
continues to hold), or $flags[1]$ will be \texttt{True}
and process~1 will be at label \texttt{@gate} (in which case the third case
will hold).
We know that process~1 never sets \texttt{turn} to 1, so
if the second case holds before the step, it will also hold after the step.
Finally, if process~1 is at label \texttt{@gate} before the step, then after
the step \texttt{turn} will equal 0, and therefore the second case will hold
after the step.  qed.

We have now demonstrated mutual exclusion in Peterson's Algorithm in two
different ways: one by letting CXL explore all possible executions, the
other using an inductive invariant and proof by induction.  The former
is certainly easier, but it does not provide intuition for why the
algorithm works.  The second provides much more insight.  We therefore
encourage to include inductive invariants in your CXL code.

A cool anecdote is the following.  When the author of CXL had to teach
Peterson's Algorithm, he refreshed his memory by looking at the Wikipedia
page.  The page claimed that the following predicate is invariant:
if process $i$ is in the critical section, then $\lnot C(i)$ (i.e.,
$I_p(i)$ without the disjunct that process $1-i$ is at label \texttt{gate}).
To demonstrate that this predicate is not invariant, you can remove the
disjunct from Figure~\ref{fig:petersonproof} and run it to get a
counterexample.

This anecdote suggests the following.  If you need to do an induction
proof of an algorithm, you have to come up with an inductive invariant.
Before trying to prove the algorithm, you can check that the predicate is
at least invariant by testing it using CXL.  Doing so could potentially
avoid wasting your time on a proof that will not work because the
predicate is not invariant, and therefore not an inductive invariant either.

To finish the story, the author of CXL fixed the Wikipedia page, but there
is another cool story.  Years later a colleague of the author, teaching
the same course, asked if the first two assignments (setting \texttt{flags[self]})
to \texttt{True} and \texttt{turn} to \texttt{1 - self}) can be reversed.
After all, they are different variables assigned independent values---in a
sequential program one could surely swap the two assignments.

\begin{quote}
What do you think?
\begin{itemize}
\item See if you can figure out for yourself if the two assignments can be
reversed.  Then run the program in Figure~\ref{fig:peterson} after reversing
the two assignments and see what happens.
\end{itemize}
\end{quote}

\begin{quote}
Bonus question!
\begin{itemize}
\item Can you generalize Peterson's algorithm to more than two processes?
\end{itemize}
\end{quote}

\chapter{CXL Methods and Pointers}

A method \texttt{m} with argument \texttt{a} is invoked in its
most basic form as follows (assigning the result to \texttt{r}).
\begin{code}
\begin{verbatim}
r = m a;
\end{verbatim}
\end{code}
That's right, no parentheses are required.  In fact, if you invoke
\texttt{m(a)}, the argument is \texttt{(a)}, which is the same
as \texttt{a}.
If you invoke \texttt{m()}, the argument is \texttt{()},
which is the empty tuple.
If you invoke \texttt{m(a, b)}, the argument is \texttt{(a, b)},
the tuple consisting of values \texttt{a} and \texttt{b}.

You may note that all this looks familiar.  Indeed, the syntax
is the same as that for dictionaries (see Chapter~\ref{ch:cxlvalues}).
Both dictionaries and methods map CXL values to CXL values,
and their syntax is indistinguishable.
If \texttt{f} is either a method or a
dictionary, and \texttt{x} is an arbitrary CXL value, then
\texttt{f x}, \texttt{f(x)}, and \texttt{f[x]} are all
the same expression in CXL.

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../PetersonMethod.cxl}
\end{code}
\caption{Peterson's Algorithm accessed through methods.}
\label{fig:petersonmethods}
\end{figure}

CXL is not an object-oriented language like Python is.  In Python
you can pass a reference to an object to a method, and that method
can then update the object.  In CXL, it is also sometimes convenient
to have a method update a shared variable specified as an argument.
For this (as well as some other uses), CXL supports \emph{pointers}
to shared variables.
If \texttt{x} is a shared variable, then the expression \texttt{\&(x)}
(the parentheses are mandatory) is a pointer to \texttt{x}
(also known as the \emph{address} of \texttt{x}).
Conversely, if \texttt{p} is a pointer to a shared variable, then the
expression \texttt{\^{}p} is the value of the shared variable.

It is often the case that methods that update shared variables through
pointers do not actually have to return a result to be useful.
In CXL, if you want to invoke a method that does not return a result
or if you are simply not interested in it,
you have to use a \texttt{call} statement like so:
\begin{code}
\begin{verbatim}
call m a;
\end{verbatim}
\end{code}

Figure~\ref{fig:petersonmethods} again shows Peterson's algorithm,
but this time with methods defined to enter and exit the critical
section.
You can put the first three methods in its own CXL source file
and include it using the CXL \texttt{import} statement.  This would
make the code re-usable by other applications.  For those who are
extra adventurous: you can add the \texttt{P\_enter} and
\texttt{P\_exit} methods to the \texttt{P\_mutex} dictionary
like so:
\begin{code}
\begin{verbatim}
dict{ .turn: 0, .flags: [ False, False ], .enter: P_enter, .exit: P_exit }
\end{verbatim}
\end{code}
That would allow you to simulate object methods.

\chapter{Spinlock}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{UpTAS.cxl}
\end{code}
\caption{Mutual Exclusion using a ``spinlock'' based on test-and-set.}
\label{fig:tas}
\end{figure}

Figure~\ref{fig:uplock} showed a faulty attempt at solving mutual
exclusion using a lock.  The problem with the implementation of the
lock is that checking the lock and setting it if it is available is
not \emph{atomic}.  Thus multiple processes contending for the lock
can all ``grab the lock'' at the same time.  While Peterson's
algorithm gets around the problem, it is not efficient, especially
if generalized to multiple processes.  Instead, multi-core processors provide
so-called \emph{interlock instructions}: special machine instructions
that can read memory and then write it in an indivisible step.

While the CXL machine does not have any built-in interlock instructions,
it does have support for executing multiple instructions atomically.
This feature is available in the CXL language in two ways.
First, any CXL statement can be made atomic by placing a label in front
of it.  Second, a group of CXL statements can be made atomic
through its \texttt{atomic}
statement.
We can use \texttt{atomic} blocks to implement a wide variety of
interlock operations.
For example, we could fix the program in Figure~\ref{fig:inc} by
constructing an atomic increment operation for a counter, like so:
\begin{code}
\begin{verbatim}
def atomic_inc(ptr):
    atomic:
        ^ptr = ^ptr + 1;
    ;
;
count = 0;
call atomic_inc &(count);
\end{verbatim}
\end{code}

Many CPUs have an atomic ``test-and-set'' operation.
Method \texttt{tas} in Figure~\ref{fig:tas} shows its specification.
Here \texttt{s} points to a shared boolean variable and \texttt{p}
to a private boolean variable, belonging to some process.
The operation copies the value of the shared variable to the
private variable (the ``test'')
and then sets the shared variable to \texttt{True} (``set'').

Figure~\ref{fig:tas} goes on how to implement mutual exclusion for
a set of $N$ processes.
It is called \emph{spinlock}, because each process is ``spinning'' until
it can acquire the lock.
The program uses $N+1$ variables.
Variable \texttt{shared} is initialized to \texttt{False} while
\texttt{private[$i$]} for each process $i$ is initialized to \texttt{True}.
An important invariant, $I_1$, of the program is that at any time at most
one of these variables is \texttt{False}.
Another invariant, $I_2(i)$, is that if process $i$ is in the critical section,
then \texttt{private[$i$] == False}.
Between the two (i.e., $I_1 \land \forall i: I_2(i)$),
it is clear that only one process can be in the
critical section at the same time.

To see that invariant $I_1$ is maintained, note that
\texttt{\^{}p == True} upon entry of \texttt{tas}.
So there are two cases:
\begin{enumerate}
\item \texttt{\^{}s} is \texttt{False} upon entry to \texttt{tas}.
Then upon exit \texttt{\^{}p == False} and \texttt{\^{}s == True}, maintaining
the invariant.
\item \texttt{\^{}s} is \texttt{True} upon entry to \texttt{tas}.
Then upon exit nothing has changed, maintaining the invariant.
\end{enumerate}
Invariant $I_1$ is also easy to verify for exiting the critical section.
Invariant $I_2(i)$ is obvious as (i) process $i$ only proceeds to the critical
section if \texttt{private[$i$] == False}, and (ii) no other process modifies
\texttt{private[$i$]}.

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{UpTASinv.cxl}
\end{code}
\caption{Checking invariants.}
\label{fig:tasinv}
\end{figure}

CXL can check these invariants as well.  Figure~\ref{fig:tas} already
has the code to check $I_2(i)$.  But how would one go about checking an
invariant like $I_1$.  Invariants must hold for every state.
For $I_2$ we only need an assertion at label \texttt{@cs} because the
premisse is that there is a process at that label.  However, we would
like to check $I_1$ in \emph{every state} (after the variables have
been initialized).

We can do this by adding another process that, in a loop,
checks the invariant.  Figure~\ref{fig:tasinv} shows the code.
Method \texttt{checkInvariant()} checks to see if the invariant holds
in a state.  It introduces a new feature of CXL: the ability to have
variables local to a method.  In this case, the variable \texttt{sum}
is used to compute the number of variables that have value
\texttt{False}.
The function is invoked by in a loop by a process that runs alongside
the other processes.
In CXL, \texttt{assert} statements are executed atomically, so the
evaluation of the assertion is not interleaved with the execution
of other processes.
Because CXL tries every possible execution, the process is guaranteed
to find violations of the invariant if it does not hold.

\begin{quote}
Try doing mutual exclusion with other interlock instructions!
\begin{itemize}
\item Find a description for \texttt{compare-and-swap} on the internet and
update Figure~\ref{fig:tas}, replacing \texttt{tas}.
\item Other interesting interlock instructions include \texttt{swap} and
\texttt{fetch-and-add}.
\end{itemize}
\end{quote}

\chapter{Locks and the Synch Module}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../TAS.cxl}
\end{code}
\caption{Fixed version of Figure~\ref{fig:uplock} using test-and-set.}
\label{fig:tas2}
\end{figure}

In Figure~\ref{fig:tas} we have shown a solution based on a shared
variable and a private variable for each process.   The private
variables themselves are actually implemented as shared variables,
but they are accessed only by their respective processes.
There is no need to keep \texttt{private} as a shared
variable---we only did so to be able to show and check the invariants.
Figure~\ref{fig:tas2} shows a more straightforward implementation of spinlock.
The solution is similar to the na\"{i}ve solution of Figure~\ref{fig:uplock},
but uses test-and-set to check and set the lock variable atomically.
This approach is general for any number of processes.

It is important to appreciate the difference between an
\emph{atomic section} (the statements executed within an
\texttt{atomic} statement) and a \emph{critical section}
(protected by a lock of some sort).
The former ensures that while the
atomic statement is executing no other process can execute.
The latter allows multiple processes to run concurrently,
just not within the critical section.
The former is rarely available to a programmer, while the latter
is very common.

In CXL, atomic statements allow you to \emph{implement} your own
low synchronization primitives like test-and-set.  Atomic statements
are not intended to \emph{replace} locks or other synchonization primitives.

\begin{figure}
\begin{code}
\begin{verbatim}
def tas(lk):
    atomic:
        result = ^lk;
        ^lk = True;
    ;
;
def lock(lk):
    while tas(lk):
        pass;
    ;
;
def unlock(lk):
    ^lk = False;
;
def Lock():
    result = False;
;
\end{verbatim}
\end{code}
\caption{The \texttt{Lock} interface in the \texttt{synch} module.}
\label{fig:locks}
\end{figure}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{UpFixed.cxl}
\end{code}
\caption{Program of Figure~\ref{fig:inc} fixed with a lock.}
\label{fig:incfixed}
\end{figure}

Locks are probably the most popular and basic form of synchronization
in concurrent programs.  For this reason, CXL has a module called
\texttt{synch} that includes support for locks.
Figure~\ref{fig:locks} shows how they are implemented, and
Figure~\ref{fig:incfixed} gives an example of how they may be used,
in this case to fix the program of Figure~\ref{fig:inc}.
Notice that the module completely hides the implementation of the
lock.
The \texttt{synch} module includes a variety of other useful
synchronization primitives, which will be discussed in later
chapters.

\chapter{Reader/Writer Locks}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../RWbusy.cxl}
\end{code}
\caption{Busy-Waiting Reader/Writer Lock implementation.}
\label{fig:rwbusy}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=2in]{figures/rdwr.jpeg}
\end{center}
\caption{High-level state diagram specification of reader/writer locks with
up to two processes.
The first number in a state gives the number of processes; the second number is the
number of processes reading in the critical section; the third is the number of
processes writing in the critical section.}
\label{fig:rdwr}
\end{figure}

Locks are useful when accessing a shared data structure.  By preventing
more than one process from accessing the data structure at the same
time, conflicting accesses are avoided.  However, not all concurrent
accesses conflict, and opportunities for concurrency may be lost,
hurting performance.  One important case is when multiple processes
are simply reading the data structure.
In many applications, reads are the majority of all accesses.
Allowing reads to proceed concurrently can significantly improve performance.

What we want is a special kind of lock that allows either one writer
or one or more readers to be in the critical section.  This is called
a \emph{reader/writer lock}~\cite{courtois71}.
We will explore various ways of implementing reader/writer locks in
this chapter and future ones.

Figure~\ref{fig:rwbusy} presents a solution that uses a
single (ordinary) lock and two counters: one that maintains the number
of readers and one that maintains the number of writers.
The lock is used to protect access to those counters.
The program shows a process that executes in a loop.
Each time, it decides whether to read or write.
The critical section is spread between two labels:
readers access \texttt{@rcs} and writers access \texttt{@wcs}.
The specification is that if a reader is at label \texttt{@rcs},
no writer is allowed to be at label \texttt{@wcs}.  Vice versa, if
a writer is at label \texttt{@wcs}, no reader is allowed to be at
label \texttt{@rcs} \emph{and} there cannot be another writer at
label \texttt{@wcs}.  Figure~\ref{fig:rdwr} shows a high-level
specification for two processes.

\begin{quote}
\begin{itemize}
\item Draw additional states and steps in Figure~\ref{fig:rdwr}
for three processes.
\end{itemize}
\end{quote}

A process that wants to read first waits until there are no writers:
\texttt{nwriters == 0}.  If so, it increments the number of readers.
Similarly, a
process that wants to write waits until there are no readers \emph{or} writers.
If so, it increments the number of writers.
The important invariants in this code are:
\begin{itemize}
\item $n$ readers at \texttt{@rcs} $\Rightarrow \mathtt{nreaders} \ge n$,
\item $n$ writers at \texttt{@wcs} $\Rightarrow \mathtt{nwriters} \ge n$,
\item $(\mathtt{nreaders} \ge 0 \land \mathtt{nwriters} = 0) \lor
    (\mathtt{nreaders} = 0 \land 0 \le \mathtt{nwriters} \le 1)$.
\end{itemize}
It is easy to see that the invariants hold and imply the reader/writer
specification.
The solution also supports progress: if no process is in the critical
section then any process can enter.  Better still: if any reader is in the
critical section, any other reader is also able to enter.

While correct, it is not considered a good solution.
The solution is an example of what is called \emph{busy-waiting}:
processes spin in a loop until some desirable condition is met.
The astute reader might wonder if obtaining an ordinary lock itself is an
example of busy-waiting.  After all, the CXL \texttt{synch} implementation
of \texttt{lock()} spins in a loop until the lock is available
(see Figure~\ref{fig:locks}).

In most operating systems and programming language runtimes, however,
when a process acquires a lock, the process is placed on a scheduling
queue and stops using CPU cycles until the lock becomes available.
Moreover, if there are multiple processes waiting for a lock, there
is a scheduler that decides which of the processes gets the lock.
Busy waiting disables all this.

But even when multiple processes each run on their own core, the solution
is inefficient.  After all, when the lock becomes available, the process
has to check other variables to see if it can continue.  In our case,
the process may have to read \texttt{nreaders} and/or \texttt{nwriters}
to decide if it can go on or has to try again, involving releasing
the lock and re-acquiring it.

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../RWlock.cxl}
\end{code}
\caption{Reader/Writer with Two Locks.}
\label{fig:rw2lock}
\end{figure}

So it is considered ok to have processes using spinlock a implement a
lock, but not to busy-wait for application-specific conditions.

Figure~\ref{fig:rw2lock} presents a reader/writer lock implementation
that does not busy-wait.
It uses two locks: \texttt{rwlock} is used by both readers and writers,
while \texttt{rlock} is only used by readers.
\texttt{rwlock} is held either when readers are at label \texttt{@rcs}
or when a writer is at label \texttt{@wcs}.
\texttt{rlock} is used to protect the \texttt{nreaders} variable that
counts the number of readers in the critical section. 

The invariants that imply the reader/writer specification
(which are again easy to verify) are as follows:

\begin{itemize}
\item $n$ readers at \texttt{@rcs} $\Rightarrow \mathtt{nreaders} \ge n$,
\item $\exists$ writer at \texttt{@wcs} $\Rightarrow \mathtt{nreaders} = 0$,
\end{itemize}

A writer simply acquires \texttt{rwlock} to enter the critical section
and releases it to exit.  The \emph{first} reader to enter the critical
section acquires \texttt{rwlock} and the \emph{last} reader to exit
the critical section releases \texttt{rwlock}.
The implementation satisfies progress: if no process is in the critical
section than any process enter.

It is instructive to see what happens when a writer is in the critical
section and two readers try to enter.  The first reader successfully
acquires \texttt{rlock} and but \emph{hangs} when trying to acquire
\texttt{rwlock}, which is held by the writer.  The second reader hangs
trying acquire \texttt{rlock} because it is held by the first reader.
When the writer leaves the critical section, the first reader acquires
\texttt{rwlock}, sets \texttt{nreaders} to 1, and releases \texttt{rlock}.
\texttt{rwlock} is still held.
Then the second reader acquires \texttt{rlock} and, assuming the first
reader is still in the critical section, increments \texttt{nreaders} to 2
and enter the critical section \emph{without} acquiring \texttt{rwlock}.
\texttt{rwlock} is essentially jointly held by both readers.
It does not matter in which order they leave: the second will release
\texttt{rwlock}.

\chapter{Semaphores}

\begin{figure}
\begin{code}
\begin{verbatim}
def Semaphore(cnt):
    result = cnt;
;
def P(sema):
    let blocked = True:
        while blocked:
            atomic:
                if (^sema) > 0:
                    ^sema = (^sema) - 1;
                    blocked = False;
                ;
            ;
        ;
    ;
;
def V(sema):
    atomic:
        ^sema = (^sema) + 1;
    ;
;
\end{verbatim}
\end{code}
\caption{The \texttt{Semaphore} interface in the \texttt{synch} module.}
\label{fig:semaphore}
\end{figure}

\begin{figure}
\begin{code}
\VerbatimInput[xleftmargin=5mm,numbers=left]{../PCsema.cxl}
\end{code}
\caption{Bounded Buffer implementation using semaphores.}
\label{fig:boundedbuffer}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=2.5in]{figures/pc.jpeg}
\end{center}
\caption{High-level state diagram specification of producers/consumers.}
\label{fig:pc}
\end{figure}

So far we have looked at how to protect a single resource.  Sometimes
we have multiple but a limited amount of resources that require
protection.  That is, if there are only $n$ resources, no more than
$n$ can be used at a time; if all are in use and a process come along
that needs one of the resources, it has to wait until another process
releases one of the resources.  Note that we cannot solve this problem
simply using a lock per resource---allocating a resource requires access
to all of them.

A good example is the so-called \emph{bounded buffer}.  It is essentially
a queue implemented using a circular buffer of a certain length and two pointers:
one where items are inserted and one from where items are extracted.  If the
buffer is full, processes that want to add more items have to wait.  In the usual
formulation, processes that want to extract an item when the buffer is empty
also have to wait.  It would be easy to build such a thing using a busy waiting
approach, but again, we would like to avoid busy waiting.

Introduced by the famous Dutch computer scientist Edsger Dijkstra,
a \emph{semaphore} is a primitive that fits the bill.  A semaphore is essentially
a counter that can be incremented and decremented but is not allowed to go
below zero.  The semaphore counter is typically initialized to the number of
resources available.  When allocating a resource, a process decrements the
counter using the \texttt{procure} or simply \texttt{P} operation.  The
\texttt{procure} operation blocks the invoking process if the counter is zero.
To release the resource, a process increments the resource using the
\texttt{vacate} or {V} operation.
Figure~\ref{fig:semaphore} shows the \texttt{synch} module implementation of
semaphores.

\chapter{Starvation}

So far we have pursued two properties: \emph{mutual exclusion}
and \emph{progress}.  The former is an example of a
\emph{safety property}---it prevents something ``bad'' from
happening, like a reader and writer process both entering the
critical section.  The \emph{progress} property is an example
of a \emph{liveness property}---guaranteeing that something good
eventually happens.
Informally (and inexactly), progress states that if no processes
are in the critical section, then some process that wants to enter
can.

Progress is a weak form of liveness.  It says that \emph{some}
process can enter, but it does not prevent a scenario such as
the following.  There are three processes repeatedly trying to
enter a critical section using a spinlock.  Two of
the processes successfully enter, alternating, but the third
process never gets a turn.  This is an example of
\texttt{starvation}.  With a spinlock, this scenario could
even happen with two processes.  Initially both processes
try to acquire the spinlock.  One of the processes is
successful and enters.  After the process leaves, it immediately
tries to re-enter.  This state is identical to the initial
state, and there is nothing that prevents the same process
from acquiring the lock yet again.

It is worth noting that Peterson's Algorithm (Chapter~\ref{ch:peterson})
does not suffer from starvation, thanks to the \texttt{turn} variable
that alternates between 0 and 1 when two processes are contending for
the critical section.

While spinlocks suffer from starvation, it is a uniform random
process and each process has an equal chance of entering the critical
section.  Thus the probability of starvation is exponentially vanishing.
Unfortunately, such is not the case for the
reader/writer solution of Figure~\ref{fig:rw2lock}.
Consider this scenario: there are two readers and one writer.  One reader
is in the critical section while the writer is waiting.  Now the
second reader tries to enter and is able to.  The first reader leaves.
We are now in a similar situation as the initial state with one reader
in the critical section and the writer waiting, but it is not the same
reader.  Unfortunately for the writer, this scenario can repeat itself
indefinitely.  So even if neither reader was in the critical section
all of the time, and the second reader arrived well after the writer,
the writer never had a chance.
In this chapter, we will present a version of a reader/writer lock
implementation that solves this type of starvation, but won't eliminate
the type of starvation that comes with spinlocks.

\end{document}
